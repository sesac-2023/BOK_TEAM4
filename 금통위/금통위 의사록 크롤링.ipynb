{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 위치 설정\n",
    "SAVE_DB_DIR = \"../data/pdf\"\n",
    "if not os.path.exists(SAVE_DB_DIR):\n",
    "    os.makedirs(SAVE_DB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.bok.or.kr/portal/bbs/B0000245/list.do?menuNo=200761'\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.content)\n",
    "\n",
    "start_page = 1\n",
    "end_page = int(soup.select('.i.end > a')[-1].attrs['href'].split('=')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1 crawling succcess\n",
      "page 2 crawling succcess\n",
      "page 3 crawling succcess\n",
      "page 4 crawling succcess\n",
      "page 5 crawling succcess\n",
      "page 6 crawling succcess\n",
      "page 7 crawling succcess\n",
      "page 8 crawling succcess\n",
      "page 9 crawling succcess\n",
      "page 10 crawling succcess\n",
      "page 11 crawling succcess\n",
      "page 12 crawling succcess\n",
      "page 13 crawling succcess\n",
      "page 14 crawling succcess\n",
      "page 15 crawling succcess\n",
      "page 16 crawling succcess\n",
      "page 17 crawling succcess\n",
      "page 18 crawling succcess\n",
      "page 19 crawling succcess\n",
      "page 20 crawling succcess\n",
      "page 21 crawling succcess\n",
      "page 22 crawling succcess\n",
      "page 23 crawling succcess\n",
      "page 24 crawling succcess\n",
      "page 25 crawling succcess\n",
      "page 26 crawling succcess\n",
      "page 27 crawling succcess\n",
      "page 28 crawling succcess\n",
      "page 29 crawling succcess\n",
      "page 30 crawling succcess\n",
      "page 31 crawling succcess\n",
      "page 32 crawling succcess\n",
      "page 33 crawling succcess\n",
      "page 34 crawling succcess\n",
      "page 35 crawling succcess\n",
      "page 36 crawling succcess\n",
      "page 37 crawling succcess\n",
      "page 38 crawling succcess\n",
      "page 39 crawling succcess\n",
      "page 40 crawling succcess\n",
      "page 41 crawling succcess\n",
      "page 42 crawling succcess\n",
      "page 43 crawling succcess\n",
      "page 44 crawling succcess\n",
      "page 45 crawling succcess\n",
      "page 46 crawling succcess\n",
      "page 47 crawling succcess\n",
      "page 48 crawling succcess\n",
      "page 49 crawling succcess\n",
      "page 50 crawling succcess\n"
     ]
    }
   ],
   "source": [
    "li_list = []\n",
    "for i in range(start_page, end_page+1):\n",
    "    url = 'http://www.bok.or.kr/portal/bbs/B0000245/list.do?menuNo=200761'\n",
    "    params = {\n",
    "    'pageIndex' : i\n",
    "    }\n",
    "    resp = requests.get(url, params = params)\n",
    "    soup = BeautifulSoup(resp.content)\n",
    "\n",
    "    li = soup.select('.bdLine.type2 > ul > li')\n",
    "    li_list.extend(li)\n",
    "    print(f\"page {i} crawling succcess\")\n",
    "    # print(li_list)\n",
    "    \n",
    "    # pdf 파일 다운로드\n",
    "    try:\n",
    "        for x in range(0, len(li_list)):\n",
    "            new_dict = {}\n",
    "            link_li = li_list[x].select('div.fileGoupBox ul li')\n",
    "\n",
    "            # 2005년 이전 데이터는 pdf파일이 존재하지 않아, 오류\n",
    "            # 2005년 이후 데이터는 pdf와 hwp 파일 모두 존재하지만, 두 파일의 순서가 제각각이라 if문을 이용하여 pdf파일만 선택함\n",
    "            for link in link_li:\n",
    "                if link.select_one('a').attrs['title'][-3:] == 'pdf':\n",
    "                    link_u = link.select_one('a').attrs['href']\n",
    "                    title = li_list[x].select_one('div.row span a span span').text\n",
    "                    url2 = 'http://www.bok.or.kr' + link_u\n",
    "\n",
    "                    # 다운로드 링크를 requests.get을 사용하여 텍스트 출력\n",
    "                    file_res2 = requests.get(url2)\n",
    "                    file_name = '{}.pdf'.format(title)\n",
    "\n",
    "                    txt_name = os.path.join(SAVE_DB_DIR, file_name)\n",
    "\n",
    "                    with open(txt_name, 'wb') as f:\n",
    "                        f.write(file_res2.content)\n",
    "                else:\n",
    "                    continue\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
